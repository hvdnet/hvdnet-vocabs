{"componentChunkName":"component---src-components-concept-jsx","path":"/w3id.org/hvdnet/statistics/ShannonEntropy.html","result":{"pageContext":{"node":{"id":"https://w3id.org/hvdnet/statistics/ShannonEntropy","type":"Concept","prefLabel":{"en":"Shannon entropy"},"altLabel":{"en":["Information entropy"]},"hiddenLabel":null,"definition":{"en":"The expected information content per symbol based on its probability distribution."},"note":null,"changeNote":null,"editorialNote":null,"historyNote":null,"scopeNote":{"en":["Estimate category probabilities (e.g., via relative frequencies) and apply the entropy formula; choose log base appropriately (e or 2)."]},"notation":null,"example":null,"narrower":[],"narrowerTransitive":[],"broader":{"id":"https://w3id.org/hvdnet/statistics/InformationContent","prefLabel":{"en":"Information Content"}},"broaderTransitive":null,"related":[],"relatedMatch":null,"broadMatch":null,"narrowMatch":null,"closeMatch":null,"exactMatch":null,"inScheme":[{"id":"https://w3id.org/hvdnet/statistics/","title":{"en":"Descriptive Statistics Vocabulary"}}],"inSchemeAll":[{"id":"https://w3id.org/hvdnet/statistics/"}],"topConceptOf":[],"deprecated":null,"isReplacedBy":null},"collections":[],"customDomain":""}},"staticQueryHashes":["1805648281","3649515864","63159454"],"slicesMap":{}}